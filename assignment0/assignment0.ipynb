{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_text(url): #Read all the .txt files in folder assignment0/ \n",
    "    content = []\n",
    "    for i in range(1,6):\n",
    "        url=\"https://raw.githubusercontent.com/hupili/python-for-data-and-media-communication-gitbook/master/assets/assignment0/trade-wars-news{}.txt\".format(i)\n",
    "        s=requests.get(url).text\n",
    "        content.append(s)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "without_punc = []  #remove all punctuations in the texts\n",
    "for elements in get_text(url):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    new_s = elements.translate(table) \n",
    "    without_punc.append(new_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cathychang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk  # To clean the data and remove the stop words, I googled the solution and found NLTK(Natural Language Toolkit) in python \n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "filtered_data = []\n",
    "lower_data = [] #lower the words in the texts\n",
    "for w in without_punc: \n",
    "    lower = str.lower(w)\n",
    "    lower_data.append(lower)\n",
    "    \n",
    "split_words = []\n",
    "for elements in lower_data: # split the string\n",
    "    splited = str.split(elements) \n",
    "    split_words.append(splited)\n",
    "\n",
    "for elements in split_words: # remove stop words\n",
    "    for w in elements:\n",
    "        if w not in en_stops:\n",
    "            filtered_data.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_stopwords = []\n",
    "stop_words = ['also', 'would', 'us', 'said'] #enrich this stop_words list to make the output more meaningful\n",
    "for w in filtered_data:\n",
    "    if w not in stop_words:\n",
    "        without_stopwords.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for word in without_stopwords:\n",
    "    dict[word] = without_stopwords.count(word)#For every word extracted above, count how many times each one appears.\n",
    "    #print(dict)\n",
    "    frequency = sorted(dict.items(), key=lambda d: d[1], reverse = True) # arrange the words frequency in ascending order\n",
    "    #print(frequency)\n",
    "import csv\n",
    "with open('assignment0.csv','w') as f: #Output the full keyword frequency list into a CSV file\n",
    "    writer = csv.writer(f)\n",
    "    header = ['keyword','frequency']\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(frequency[:15])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
